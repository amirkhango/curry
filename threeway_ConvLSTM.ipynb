{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:  1.2570787221094177\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" \n",
    "Usage:\n",
    "    THEANO_FLAGS=\"device=gpu0\" python exptBikeNYC.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from deepst.models.threewayConvLSTM import threeway\n",
    "from deepst.config import Config\n",
    "import deepst.metrics as metrics\n",
    "from deepst.datasets import BikeNYC\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "# parameters\n",
    "# data path, you may set your own data path with the global envirmental\n",
    "# variable DATAPATH\n",
    "DATAPATH = Config().DATAPATH\n",
    "nb_epoch = 5  # number of epoch at training stage\n",
    "nb_epoch_cont = 1  # number of epoch at training (cont) stage\n",
    "batch_size = 1  # batch size\n",
    "T = 24  # number of time intervals in one day\n",
    "\n",
    "lr = 0.0002  # learning rate\n",
    "len_closeness = 3  # length of closeness dependent sequence\n",
    "len_period = 2  # length of peroid dependent sequence\n",
    "len_trend = 2  # length of trend dependent sequence\n",
    "nb_residual_unit = 4   # number of residual units\n",
    "ConvLstmLayers = 1 # depth of ConvLstmLayers\n",
    "\n",
    "nb_flow = 2  # there are two types of flows: new-flow and end-flow\n",
    "# divide data into two subsets: Train & Test, of which the test set is the\n",
    "# last 10 days\n",
    "days_test = 10\n",
    "len_test = T * days_test\n",
    "map_height, map_width = 16, 8  # grid size\n",
    "# For NYC Bike data, there are 81 available grid-based areas, each of\n",
    "# which includes at least ONE bike station. Therefore, we modify the final\n",
    "# RMSE by multiplying the following factor (i.e., factor).\n",
    "nb_area = 81\n",
    "m_factor = math.sqrt(1. * map_height * map_width / nb_area)\n",
    "print('factor: ', m_factor)\n",
    "path_result = 'Test_RET'\n",
    "path_model = 'Test_MODEL'\n",
    "\n",
    "if os.path.isdir(path_result) is False:\n",
    "    os.mkdir(path_result)\n",
    "if os.path.isdir(path_model) is False:\n",
    "    os.mkdir(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(external_dim=None):\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "    p_conf = (len_period, nb_flow, map_height,\n",
    "              map_width) if len_period > 0 else None\n",
    "    t_conf = (len_trend, nb_flow, map_height,\n",
    "              map_width) if len_trend > 0 else None\n",
    "\n",
    "    model = threeway(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n",
    "                     external_dim=external_dim)\n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n",
    "    model.summary()\n",
    "    # from keras.utils.visualize_util import plot\n",
    "    # plot(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "h5 data shape: (4392, 2, 16, 8)\n",
      "h5 timestamps data shape: (4392,)\n",
      "The first 3 timestamps are: [b'2014040101' b'2014040102' b'2014040103']\n",
      "The Last 3 timestamps are: [b'2014093022' b'2014093023' b'2014093024']\n",
      "incomplete days:  []\n",
      "sequences of all data shape is: (4392, 2, 16, 8)\n",
      "len_test is 240\n",
      "sequences of data_train  shape:  (4152, 2, 16, 8)\n",
      "min: 0.0 max: 267.0\n",
      "length of data_all is 1\n",
      "d len is (4392, 2, 16, 8)\n",
      "[mmn] length is 1\n",
      "length of data_all_mmn is 1\n",
      "length of timestamps_all is 1\n",
      "The last time stamp is 2014 9 30 23\n",
      "Pandas Timestamp is [Timestamp('2014-09-30 23:00:00')]\n",
      "TrendInterval is 7, len_trend is 2,             PeriodInterval is 1, len_period is 2,            ,len_closeness is 3, self.T is24\n",
      "max i is: 336\n",
      "X_ALL shape is: (4056, 14, 16, 8)\n",
      "len_test is 240\n",
      "XC shape:  (4056, 6, 16, 8) XP shape:  (4056, 4, 16, 8) XT shape:  (4056, 4, 16, 8) Y shape: (4056, 2, 16, 8)\n",
      "Convert for LSTM input shape: (3816, 3, 2, 16, 8)\n",
      "Convert for LSTM input shape: (3816, 2, 2, 16, 8)\n",
      "Convert for LSTM input shape: (3816, 2, 2, 16, 8)\n",
      "train shape: (3816, 6, 16, 8) (3816, 2, 16, 8) test shape:  (240, 6, 16, 8) (240, 2, 16, 8)\n",
      "meta_feature shape is: (4056, 8)\n",
      "hahahahahahaha\n",
      "(3816, 3, 2, 16, 8)\n",
      "hahahahahahaha\n",
      "(3816, 2, 2, 16, 8)\n",
      "hahahahahahaha\n",
      "(3816, 2, 2, 16, 8)\n",
      "hahahahahahaha\n",
      "(3816, 8)\n",
      "\n",
      "(240, 6, 16, 8)\n",
      "(240, 4, 16, 8)\n",
      "(240, 4, 16, 8)\n",
      "(240, 8)\n",
      "\n",
      "\n",
      " days (test):  [b'20140921', b'20140922', b'20140923', b'20140924', b'20140925', b'20140926', b'20140927', b'20140928', b'20140929', b'20140930']\n",
      "==========\n",
      "compiling model...\n",
      "**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\n",
      "external_dim is: 8\n",
      "outputs length: 3\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, None, 2, 16, 8 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, None, 2, 16, 8 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (None, None, 2, 16, 8 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)      (None, 32, 16, 8)     39296       input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)      (None, 32, 16, 8)     39296       input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)      (None, 32, 16, 8)     39296       input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            90          input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 32, 16, 8)     32          conv_lst_m2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 32, 16, 8)     32          conv_lst_m2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 32, 16, 8)     32          conv_lst_m2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 10)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 2, 16, 8)      578         batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 2, 16, 8)      578         batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 2, 16, 8)      578         batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 256)           2816        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "i_layer_4 (iLayer)               (None, 2, 16, 8)      256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "i_layer_5 (iLayer)               (None, 2, 16, 8)      256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "i_layer_6 (iLayer)               (None, 2, 16, 8)      256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 256)           0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 2, 16, 8)      0           i_layer_4[0][0]                  \n",
      "                                                                   i_layer_5[0][0]                  \n",
      "                                                                   i_layer_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 2, 16, 8)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 2, 16, 8)      0           add_3[0][0]                      \n",
      "                                                                   reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2, 16, 8)      0           add_4[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 123,392\n",
      "Trainable params: 123,344\n",
      "Non-trainable params: 48\n",
      "____________________________________________________________________________________________________\n",
      "=========="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kudou/anaconda2/envs/py35/lib/python3.5/site-packages/keras/engine/topology.py:621: UserWarning: Class `deepst.models.iLayer.iLayer` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n",
      "  output_shape = self.compute_output_shape(input_shape)\n",
      "/Users/kudou/codes/DeepSTtest/deepst/models/threewayConvLSTM.py:70: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10)`\n",
      "  embedding = Dense(output_dim=10)(external_input)\n",
      "/Users/kudou/codes/DeepSTtest/deepst/models/threewayConvLSTM.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=256)`\n",
      "  h1 = Dense(output_dim=nb_flow * map_height * map_width)(embedding)\n",
      "/Users/kudou/codes/DeepSTtest/deepst/models/threewayConvLSTM.py:80: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n",
      "  model = Model(input=main_inputs, output=main_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training model...\n",
      "Train on 3434 samples, validate on 382 samples\n",
      "Epoch 1/5\n",
      " 331/3434 [=>............................] - ETA: 222s - loss: 0.0437 - rmse: 0.1626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kudou/anaconda2/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d68c6e6a8218>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d68c6e6a8218>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m     36\u001b[0m     model.save_weights(os.path.join(\n\u001b[1;32m     37\u001b[0m         path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"loading data...\")\n",
    "    # data_numbers=None will use all data, this could be very slowly.\n",
    "    # data_numbers=800 will use only 800 series for trying on small data.\n",
    "    X_train_ALL, X_test_ALL, X_train, Y_train, X_test, Y_test, mmn, external_dim, timestamp_train, timestamp_test = BikeNYC.load_threeway_data(\n",
    "        T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n",
    "        preprocess_name='preprocessing.pkl', meta_data=True, data_numbers=None )\n",
    "\n",
    "    print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"compiling model...\")\n",
    "    print(\n",
    "        \"**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\")\n",
    "    print('external_dim is:', external_dim)\n",
    "    \n",
    "    \n",
    "    model = build_model(external_dim)\n",
    "    hyperparams_name = 'threeway_c{}.p{}.t{}.ConvLstmLayers{}.lr{}'.format(\n",
    "        len_closeness, len_period, len_trend,ConvLstmLayers , lr)\n",
    "    fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_rmse', patience=5, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"training model...\")\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        verbose=1)\n",
    "    model.save_weights(os.path.join(\n",
    "        path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n",
    "    pickle.dump((history.history), open(os.path.join(\n",
    "        path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "\n",
    "    print('=' * 10)\n",
    "    print('evaluating using the model that has the best loss on the valid set')\n",
    "\n",
    "    model.load_weights(fname_param)\n",
    "    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                           0] // 48, verbose=0)\n",
    "    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "    score = model.evaluate(\n",
    "        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"training model (cont)...\")\n",
    "    fname_param = os.path.join(\n",
    "        path_model, '{}.cont.best.h5'.format(hyperparams_name))\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        fname_param, monitor='rmse', verbose=0, save_best_only=True, mode='min')\n",
    "    history = model.fit(X_train, Y_train, nb_epoch=nb_epoch_cont, verbose=1, batch_size=batch_size, callbacks=[\n",
    "                        model_checkpoint], validation_data=(X_test_ALL, Y_test))\n",
    "    pickle.dump((history.history), open(os.path.join(\n",
    "        path_result, '{}.cont.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "    model.save_weights(os.path.join(\n",
    "        path_model, '{}_cont.h5'.format(hyperparams_name)), overwrite=True)\n",
    "\n",
    "    print('=' * 10)\n",
    "    print('evaluating using the final model')\n",
    "    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                           0] // 48, verbose=0)\n",
    "    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "    score = model.evaluate(\n",
    "        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
