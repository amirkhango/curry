{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test!\n",
      "factor:  1.2570787221094177\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" \n",
    "Usage:\n",
    "    THEANO_FLAGS=\"device=gpu0\" python exptBikeNYC.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from deepst.models.threewayConvLSTM import threeway\n",
    "from deepst.config import Config\n",
    "import deepst.metrics as metrics\n",
    "from deepst.datasets import BikeNYC\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "# parameters\n",
    "# data path, you may set your own data path with the global envirmental\n",
    "# variable DATAPATH\n",
    "DATAPATH = Config().DATAPATH\n",
    "nb_epoch = 40  # number of epoch at training stage\n",
    "nb_epoch_cont = 10  # number of epoch at training (cont) stage\n",
    "batch_size = 1  # batch size\n",
    "T = 24  # number of time intervals in one day\n",
    "\n",
    "lr = 0.0002  # learning rate\n",
    "len_closeness = 3  # length of closeness dependent sequence\n",
    "len_period = 2  # length of peroid dependent sequence\n",
    "len_trend = 2  # length of trend dependent sequence\n",
    "nb_residual_unit = 4   # number of residual units\n",
    "ConvLstmLayers = 1 # depth of ConvLstmLayers\n",
    "\n",
    "nb_flow = 2  # there are two types of flows: new-flow and end-flow\n",
    "# divide data into two subsets: Train & Test, of which the test set is the\n",
    "# last 10 days\n",
    "days_test = 10\n",
    "len_test = T * days_test\n",
    "map_height, map_width = 16, 8  # grid size\n",
    "# For NYC Bike data, there are 81 available grid-based areas, each of\n",
    "# which includes at least ONE bike station. Therefore, we modify the final\n",
    "# RMSE by multiplying the following factor (i.e., factor).\n",
    "nb_area = 81\n",
    "m_factor = math.sqrt(1. * map_height * map_width / nb_area)\n",
    "print('factor: ', m_factor)\n",
    "path_result = 'Test_RET'\n",
    "path_model = 'Test_MODEL'\n",
    "\n",
    "if os.path.isdir(path_result) is False:\n",
    "    os.mkdir(path_result)\n",
    "if os.path.isdir(path_model) is False:\n",
    "    os.mkdir(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(external_dim=None):\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "    p_conf = (len_period, nb_flow, map_height,\n",
    "              map_width) if len_period > 0 else None\n",
    "    t_conf = (len_trend, nb_flow, map_height,\n",
    "              map_width) if len_trend > 0 else None\n",
    "\n",
    "    model = threeway(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n",
    "                     external_dim=external_dim)\n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n",
    "    model.summary()\n",
    "    # from keras.utils.visualize_util import plot\n",
    "    # plot(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "h5 data shape: (1800, 2, 16, 8)\n",
      "h5 timestamps data shape: (1800,)\n",
      "The first 3 timestamps are: [b'2014040101' b'2014040102' b'2014040103']\n",
      "The Last 3 timestamps are: [b'2014061422' b'2014061423' b'2014061424']\n",
      "incomplete days:  []\n",
      "sequences of all data shape is: (1800, 2, 16, 8)\n",
      "len_test is 240\n",
      "sequences of data_train  shape:  (1560, 2, 16, 8)\n",
      "min: 0.0 max: 237.0\n",
      "length of data_all is 1\n",
      "d len is (1800, 2, 16, 8)\n",
      "[mmn] length is 1\n",
      "length of data_all_mmn is 1\n",
      "length of timestamps_all is 1\n",
      "The last time stamp is 2014 6 14 23\n",
      "Pandas Timestamp is [Timestamp('2014-06-14 23:00:00')]\n",
      "TrendInterval is 7, len_trend is 2,             PeriodInterval is 1, len_period is 2,            ,len_closeness is 3, self.T is24\n",
      "max i is: 336\n",
      "X_ALL shape is: (1464, 14, 16, 8)\n",
      "len_test is 240\n",
      "XC shape:  (1464, 6, 16, 8) XP shape:  (1464, 4, 16, 8) XT shape:  (1464, 4, 16, 8) Y shape: (1464, 2, 16, 8)\n",
      "Convert for LSTM input shape: (1224, 3, 2, 16, 8)\n",
      "Convert for LSTM input shape: (1224, 2, 2, 16, 8)\n",
      "Convert for LSTM input shape: (1224, 2, 2, 16, 8)\n",
      "Convert for LSTM input shape: (240, 3, 2, 16, 8)\n",
      "Convert for LSTM input shape: (240, 2, 2, 16, 8)\n",
      "Convert for LSTM input shape: (240, 2, 2, 16, 8)\n",
      "train shape: (1224, 6, 16, 8) (1224, 2, 16, 8) test shape:  (240, 6, 16, 8) (240, 2, 16, 8)\n",
      "meta_feature shape is: (1464, 8)\n",
      "(1224, 3, 2, 16, 8)\n",
      "(1224, 2, 2, 16, 8)\n",
      "(1224, 2, 2, 16, 8)\n",
      "(1224, 8)\n",
      "\n",
      "(240, 3, 2, 16, 8)\n",
      "(240, 2, 2, 16, 8)\n",
      "(240, 2, 2, 16, 8)\n",
      "(240, 8)\n",
      "\n",
      "\n",
      " days (test):  [b'20140605', b'20140606', b'20140607', b'20140608', b'20140609', b'20140610', b'20140611', b'20140612', b'20140613', b'20140614']\n",
      "==========\n",
      "compiling model...\n",
      "**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\n",
      "external_dim is: 8\n",
      "outputs length: 3\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, None, 2, 16, 8 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, None, 2, 16, 8 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (None, None, 2, 16, 8 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)      (None, 32, 16, 8)     39296       input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)      (None, 32, 16, 8)     39296       input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)      (None, 32, 16, 8)     39296       input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            90          input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 32, 16, 8)     32          conv_lst_m2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 32, 16, 8)     32          conv_lst_m2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 32, 16, 8)     32          conv_lst_m2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 10)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 2, 16, 8)      578         batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 2, 16, 8)      578         batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 2, 16, 8)      578         batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 256)           2816        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "i_layer_4 (iLayer)               (None, 2, 16, 8)      256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "i_layer_5 (iLayer)               (None, 2, 16, 8)      256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "i_layer_6 (iLayer)               (None, 2, 16, 8)      256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 256)           0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 2, 16, 8)      0           i_layer_4[0][0]                  \n",
      "                                                                   i_layer_5[0][0]                  \n",
      "                                                                   i_layer_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 2, 16, 8)      0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 2, 16, 8)      0           add_3[0][0]                      \n",
      "                                                                   reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 2, 16, 8)      0           add_4[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 123,392\n",
      "Trainable params: 123,344\n",
      "Non-trainable params: 48\n",
      "____________________________________________________________________________________________________\n",
      "==========\n",
      "training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kudou/anaconda2/envs/py35/lib/python3.5/site-packages/keras/engine/topology.py:621: UserWarning: Class `deepst.models.iLayer.iLayer` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n",
      "  output_shape = self.compute_output_shape(input_shape)\n",
      "/Users/kudou/codes/DeepSTtest/deepst/models/threewayConvLSTM.py:70: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10)`\n",
      "  embedding = Dense(output_dim=10)(external_input)\n",
      "/Users/kudou/codes/DeepSTtest/deepst/models/threewayConvLSTM.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=256)`\n",
      "  h1 = Dense(output_dim=nb_flow * map_height * map_width)(embedding)\n",
      "/Users/kudou/codes/DeepSTtest/deepst/models/threewayConvLSTM.py:80: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n",
      "  model = Model(input=main_inputs, output=main_output)\n",
      "/Users/kudou/anaconda2/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1101 samples, validate on 123 samples\n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 66s - loss: 0.0283 - rmse: 0.1254 - val_loss: 0.0130 - val_rmse: 0.0994\n",
      "==========\n",
      "evaluating using the model that has the best loss on the valid set\n",
      "Train score: 0.010386 rmse (norm): 0.100513 rmse (real): 14.972829\n",
      "Test score: 0.011056 rmse (norm): 0.105148 rmse (real): 15.663292\n",
      "==========\n",
      "training model (cont)...\n",
      "Train on 1224 samples, validate on 240 samples\n",
      "Epoch 1/1\n",
      "   3/1224 [..............................] - ETA: 59s - loss: 0.0071 - rmse: 0.0743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kudou/anaconda2/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:62: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 999/1224 [=======================>......] - ETA: 11s - loss: 0.0090 - rmse: 0.0845"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"loading data...\")\n",
    "    # data_numbers=None will use all data, this could be very slowly.\n",
    "    # data_numbers=800 will use only 800 series for trying on small data.\n",
    "    X_train_ALL, X_test_ALL, X_train, Y_train, X_test, Y_test, mmn, external_dim, timestamp_train, timestamp_test = BikeNYC.load_threeway_data(\n",
    "        T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n",
    "        preprocess_name='preprocessing.pkl', meta_data=True, data_numbers=None )\n",
    "\n",
    "    print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"compiling model...\")\n",
    "    print(\n",
    "        \"**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\")\n",
    "    print('external_dim is:', external_dim)\n",
    "    \n",
    "    \n",
    "    model = build_model(external_dim)\n",
    "    hyperparams_name = 'threeway_c{}.p{}.t{}.ConvLstmLayers{}.lr{}'.format(\n",
    "        len_closeness, len_period, len_trend,ConvLstmLayers , lr)\n",
    "    fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_rmse', patience=5, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"training model...\")\n",
    "    \n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        verbose=1)\n",
    "    model.save_weights(os.path.join(\n",
    "        path_model, '{}.h5'.format(hyperparams_name)), overwrite=True)\n",
    "    pickle.dump((history.history), open(os.path.join(\n",
    "        path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "\n",
    "    print('=' * 10)\n",
    "    print('evaluating using the model that has the best loss on the valid set')\n",
    "\n",
    "    model.load_weights(fname_param)\n",
    "    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                           0] // 48, verbose=0)\n",
    "    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "    score = model.evaluate(\n",
    "        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "    print('=' * 10)\n",
    "    print(\"training model (cont)...\")\n",
    "    fname_param = os.path.join(\n",
    "        path_model, '{}.cont.best.h5'.format(hyperparams_name))\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        fname_param, monitor='rmse', verbose=0, save_best_only=True, mode='min')\n",
    "    history = model.fit(X_train, Y_train, nb_epoch=nb_epoch_cont, verbose=1, batch_size=batch_size, callbacks=[\n",
    "                        model_checkpoint], validation_data=(X_test, Y_test))\n",
    "    pickle.dump((history.history), open(os.path.join(\n",
    "        path_result, '{}.cont.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "    model.save_weights(os.path.join(\n",
    "        path_model, '{}_cont.h5'.format(hyperparams_name)), overwrite=True)\n",
    "\n",
    "    print('=' * 10)\n",
    "    print('evaluating using the final model')\n",
    "    score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                           0] // 48, verbose=0)\n",
    "    print('Train score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "    score = model.evaluate(\n",
    "        X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "    print('Test score: %.6f rmse (norm): %.6f rmse (real): %.6f' %\n",
    "          (score[0], score[1], score[1] * (mmn._max - mmn._min) / 2. * m_factor))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
