{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'channels_first'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from deepst.models.STResNet import stresnet\n",
    "from deepst.models.STConvolution import binCNN_CPTM\n",
    "from deepst.config import Config\n",
    "import deepst.metrics as metrics\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from testmodel import stresnet as st\n",
    "from deepst.datasets import BikeNYC\n",
    "from importlib import reload\n",
    "BikeNYC=reload(BikeNYC)\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor:  1.2570787221094177\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "# data path, you may set your own data path with the global envirmental\n",
    "# variable DATAPATH\n",
    "DATAPATH = Config().DATAPATH\n",
    "nb_epoch = 500  # number of epoch at training stage\n",
    "nb_epoch_cont = 100  # number of epoch at training (cont) stage\n",
    "batch_size = 32  # batch size\n",
    "T = 24  # number of time intervals in one day\n",
    "\n",
    "lr = 0.0002  # learning rate\n",
    "len_closeness = 3  # length of closeness dependent sequence\n",
    "len_period = 4  # length of peroid dependent sequence\n",
    "len_trend = 4  # length of trend dependent sequence\n",
    "nb_residual_unit = 4   # number of residual units\n",
    "\n",
    "nb_flow = 2  # there are two types of flows: new-flow and end-flow\n",
    "# divide data into two subsets: Train & Test, of which the test set is the\n",
    "# last 10 da ys\n",
    "days_test = 10\n",
    "len_test = T * days_test\n",
    "map_height, map_width = 16, 8  # grid size\n",
    "# For NYC Bike data, there are 81 available grid-based areas, each of\n",
    "# which includes at least ONE bike station. Therefore, we modify the final\n",
    "# RMSE by multiplying the following factor (i.e., factor).\n",
    "nb_area = 81\n",
    "m_factor = math.sqrt(1. * map_height * map_width / nb_area)\n",
    "print('factor: ', m_factor)\n",
    "path_result = 'Test_RET'\n",
    "path_model = 'Test_MODEL'\n",
    "if os.path.isdir(path_result) is False:\n",
    "    os.mkdir(path_result)\n",
    "if os.path.isdir(path_model) is False:\n",
    "    os.mkdir(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(external_dim):\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "    p_conf = (len_period, nb_flow, map_height,\n",
    "              map_width) if len_period > 0 else None\n",
    "    t_conf = (len_trend, nb_flow, map_height,\n",
    "              map_width) if len_trend > 0 else None\n",
    "\n",
    "    #model = st(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n",
    "    #                 external_dim=external_dim, nb_residual_unit=nb_residual_unit)\n",
    "    \n",
    "    model = binCNN(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf)\n",
    "    \n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(external_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file= os.path.join(path_model,'binCNN.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "h5 data shape: (1500, 2, 16, 8)\n",
      "h5 timestamps data shape: (1500,)\n",
      "The first 3 timestamps are: [b'2014040101' b'2014040102' b'2014040103']\n",
      "The Last 3 timestamps are: [b'2014060210' b'2014060211' b'2014060212']\n",
      "incomplete days:  [b'20140602']\n",
      "sequences of all data shape is: (1488, 2, 16, 8)\n",
      "len_test is 240\n",
      "sequences of data_train  shape:  (1248, 2, 16, 8)\n",
      "min: 0.0 max: 237.0\n",
      "length of data_all is 1\n",
      "[mmn] lenght is 1\n",
      "length of data_all_mmn is 1\n",
      "length of timestamps_all is 1\n",
      "The last time stamp is 2014 6 1 23\n",
      "Pandas Timestamp is [Timestamp('2014-06-01 23:00:00')]\n",
      "TrendInterval is 7, len_trend is 4,             PeriodInterval is 1, len_period is 4,            ,len_closeness is 3, self.T is24\n",
      "max i is: 672\n",
      "X_ALL shape is: (816, 22, 16, 8)\n",
      "len_test is 240\n",
      "XC shape:  (816, 6, 16, 8) XP shape:  (816, 8, 16, 8) XT shape:  (816, 8, 16, 8) Y shape: (816, 2, 16, 8)\n",
      "l is 3\n",
      "l is 4\n",
      "l is 4\n",
      "train shape: (576, 6, 16, 8) (576, 2, 16, 8) test shape:  (240, 6, 16, 8) (240, 2, 16, 8)\n",
      "(576, 6, 16, 8)\n",
      "(576, 8, 16, 8)\n",
      "(576, 8, 16, 8)\n",
      "\n",
      "(240, 6, 16, 8)\n",
      "(240, 8, 16, 8)\n",
      "(240, 8, 16, 8)\n",
      "\n",
      "\n",
      " days (test):  [b'20140523', b'20140524', b'20140525', b'20140526', b'20140527', b'20140528', b'20140529', b'20140530', b'20140531', b'20140601']\n",
      "==========\n",
      "compiling model...\n",
      "**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\n",
      "external_dim is: None\n"
     ]
    }
   ],
   "source": [
    "print(\"loading data...\")\n",
    "three_models = True # If true, split Closeness, Period and Trend into 3 sub-CNN respectively.\n",
    "\n",
    "# data_numbers=None will use all data, this could be very slowly.\n",
    "# data_numbers=800 will use only 800 series for trying on small data.\n",
    "X_train_ALL, X_test_ALL, X_train, Y_train, X_test, Y_test, mmn, external_dim, timestamp_train, timestamp_test = BikeNYC.load_data(\n",
    "    T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n",
    "    preprocess_name='preprocessing.pkl', meta_data=False, data_numbers=1500)\n",
    "\n",
    "print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n",
    "\n",
    "print('=' * 10)\n",
    "print(\"compiling model...\")\n",
    "print(\n",
    "    \"**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\")\n",
    "print('external_dim is:', external_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_name = 'binCNN_c{}.p{}.t{}.resunit{}.lr{}'.format(\\\n",
    "    len_closeness, len_period, len_trend, nb_residual_unit, lr)\n",
    "fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_rmse', patience=5, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "print('=' * 10)\n",
    "print(\"training model...\")\n",
    "history = model.fit(X_train_ALL, Y_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepst.models.STConvolution import binCNN_CPTM\n",
    "def build_model2(external_dim):\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "    p_conf = (len_period, nb_flow, map_height,\n",
    "              map_width) if len_period > 0 else None\n",
    "    t_conf = (len_trend, nb_flow, map_height,\n",
    "              map_width) if len_trend > 0 else None\n",
    "\n",
    "    #model = st(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf,\n",
    "    #                 external_dim=external_dim, nb_residual_unit=nb_residual_unit)\n",
    "    \n",
    "    model = binCNN_CPTM(c_conf=c_conf, p_conf=p_conf, t_conf=t_conf, metadata_dim=8)\n",
    "    \n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n",
    "    model.summary()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_inputs shape is: (22, 16, 8, 8)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 16, 8)         12736     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 16, 8)        73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 16, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 16, 8)         73792     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 16, 8)          1154      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 16, 8)          0         \n",
      "=================================================================\n",
      "Total params: 161,538\n",
      "Trainable params: 161,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 2, 16, 8)          0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 16, 8)          0         \n",
      "=================================================================\n",
      "Total params: 163,842\n",
      "Trainable params: 163,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kudou/codes/DeepSTtest/deepst/models/STConvolution.py:73: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  model_final.add(Merge([model, metadata_processor], mode='sum'))\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model2(external_dim=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model2, to_file= os.path.join(path_model,'binCNN_CPTM.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "h5 data shape: (1500, 2, 16, 8)\n",
      "h5 timestamps data shape: (1500,)\n",
      "The first 3 timestamps are: [b'2014040101' b'2014040102' b'2014040103']\n",
      "The Last 3 timestamps are: [b'2014060210' b'2014060211' b'2014060212']\n",
      "incomplete days:  [b'20140602']\n",
      "sequences of all data shape is: (1488, 2, 16, 8)\n",
      "len_test is 240\n",
      "sequences of data_train  shape:  (1248, 2, 16, 8)\n",
      "min: 0.0 max: 237.0\n",
      "length of data_all is 1\n",
      "[mmn] lenght is 1\n",
      "length of data_all_mmn is 1\n",
      "length of timestamps_all is 1\n",
      "The last time stamp is 2014 6 1 23\n",
      "Pandas Timestamp is [Timestamp('2014-06-01 23:00:00')]\n",
      "TrendInterval is 7, len_trend is 4,             PeriodInterval is 1, len_period is 4,            ,len_closeness is 3, self.T is24\n",
      "max i is: 672\n",
      "X_ALL shape is: (816, 22, 16, 8)\n",
      "len_test is 240\n",
      "XC shape:  (816, 6, 16, 8) XP shape:  (816, 8, 16, 8) XT shape:  (816, 8, 16, 8) Y shape: (816, 2, 16, 8)\n",
      "l is 3\n",
      "l is 4\n",
      "l is 4\n",
      "train shape: (576, 6, 16, 8) (576, 2, 16, 8) test shape:  (240, 6, 16, 8) (240, 2, 16, 8)\n",
      "meta_feature shape is: (816, 8)\n",
      "(576, 6, 16, 8)\n",
      "(576, 8, 16, 8)\n",
      "(576, 8, 16, 8)\n",
      "(576, 8)\n",
      "\n",
      "(240, 6, 16, 8)\n",
      "(240, 8, 16, 8)\n",
      "(240, 8, 16, 8)\n",
      "(240, 8)\n",
      "\n",
      "\n",
      " days (test):  [b'20140523', b'20140524', b'20140525', b'20140526', b'20140527', b'20140528', b'20140529', b'20140530', b'20140531', b'20140601']\n",
      "==========\n",
      "compiling model...\n",
      "**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\n",
      "external_dim is: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"loading data...\")\n",
    "three_models = True # If true, split Closeness, Period and Trend into 3 sub-CNN respectively.\n",
    "\n",
    "# data_numbers=None will use all data, this could be very slowly.\n",
    "# data_numbers=800 will use only 800 series for trying on small data.\n",
    "X_train_ALL, X_test_ALL, X_train, Y_train, X_test, Y_test, mmn, external_dim, timestamp_train, timestamp_test = BikeNYC.load_data(\n",
    "    T=T, nb_flow=nb_flow, len_closeness=len_closeness, len_period=len_period, len_trend=len_trend, len_test=len_test,\n",
    "    preprocess_name='preprocessing.pkl', meta_data=True, data_numbers=1500)\n",
    "\n",
    "print(\"\\n days (test): \", [v[:8] for v in timestamp_test[0::T]])\n",
    "\n",
    "print('=' * 10)\n",
    "print(\"compiling model...\")\n",
    "print(\n",
    "    \"**at the first time, it takes a few minites to compile if you use [Theano] as the backend**\")\n",
    "print('external_dim is:', external_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train_ALL shape is:', X_train_ALL[0].shape, X_train_ALL[1].shape )\n",
    "print('X_test_ALL shape is:', X_test_ALL[0].shape, X_test_ALL[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "training model...\n",
      "Train on 518 samples, validate on 58 samples\n",
      "Epoch 1/500\n",
      "518/518 [==============================] - 4s - loss: 0.3121 - rmse: 0.4949 - val_loss: 0.0666 - val_rmse: 0.2579\n",
      "Epoch 2/500\n",
      "352/518 [===================>..........] - ETA: 1s - loss: 0.0595 - rmse: 0.2439"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ec41f080d4c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams_name = 'binCNN_CPTM_c{}.p{}.t{}.resunit{}.lr{}'.format(\n",
    "    len_closeness, len_period, len_trend, nb_residual_unit, lr)\n",
    "fname_param = os.path.join(path_model, '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_rmse', patience=5, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "print('=' * 10)\n",
    "print(\"training model...\")\n",
    "\n",
    "history = model2.fit(X_train_ALL, Y_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
